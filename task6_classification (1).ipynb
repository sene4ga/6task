{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-Mb7bnoaRLM"
      },
      "source": [
        "# Логичтическая регрессия, метод опорных векторов, one-hot кодирование"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNyXo3CvaRLP"
      },
      "source": [
        "### О задании\n",
        "\n",
        "В этом задании вы:\n",
        "- настроите метод опорных векторов\n",
        "- изучите методы работы с категориальными переменными"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ndj090dOaRLQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder as OHE\n",
        "import copy\n",
        "from joblib import Parallel, delayed\n",
        "import warnings, time\n",
        "import numpy as np\n",
        "warnings.simplefilter(action='ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_wS0x7RaRLR"
      },
      "source": [
        "__Задание 1.__ Обучение логистической регрессии на реальных данных и оценка качества классификации.\n",
        "\n",
        "**(5 баллов)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94eHa5RgaRLS"
      },
      "source": [
        "Загрузим данные с конкурса [Kaggle Porto Seguro’s Safe Driver Prediction](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction) (вам нужна только обучающая выборка). Задача состоит в определении водителей, которые в ближайший год воспользуются своей автомобильной страховкой (бинарная классификация). Но для нас важна будет не сама задача, а только её данные. При этом под нужды задания мы немного модифицируем датасет."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "BJQn-94DaRLS"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('train.csv', index_col=0)\n",
        "target = data.target.values\n",
        "data = data.drop('target', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2Su7GNhaRLT"
      },
      "source": [
        "Пересемплируем выборку так, чтобы положительных и отрицательных объектов в выборке было одинаковое число. Разделим на обучающую и тестовую выборки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "fot9A7L8aRLT"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "mask_plus = np.random.choice(np.where(target == 1)[0], 100000, replace=True)\n",
        "mask_zero = np.random.choice(np.where(target == 0)[0], 100000, replace=True)\n",
        "mask = np.concatenate([mask_plus, mask_zero])\n",
        "mask = np.sort(mask)\n",
        "\n",
        "data = data.iloc[mask]\n",
        "target = target[mask]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GB0kVSoaRLT"
      },
      "source": [
        "Не забудьте отнормировать признаки (можно воспользоваться StandardScaler или сделать это вручную). Пока не будем обращать внимание на то, что некоторые признаки категориальные (этим мы займёмся позже)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "5dDctZhDaRLU"
      },
      "outputs": [],
      "source": [
        "def scall(data):\n",
        "    new_data = copy.deepcopy(data)\n",
        "    scaler = StandardScaler()\n",
        "    new_data[new_data.select_dtypes(include=['float64', 'int64']).columns] = scaler.fit_transform(new_data.select_dtypes(include=['float64', 'int64']))\n",
        "\n",
        "    return new_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSrjeimpaRLU"
      },
      "source": [
        "Обучите логистическую регрессию с удобными для вас параметрами, примените регуляризацию. Сделайте предсказание на тестовой части выборки. Посчитайте accuracy, precision, recall и F меру"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "A1tEHyNFaRLU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53db7da9-a71a-45f1-f92b-7ac4a023ba3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.59124\n",
            "Precision: 0.5975506665221633\n",
            "Recall: 0.5527196904384787\n",
            "F1 Score: 0.5742615506395033\n",
            "Time taken: 0.5159845352172852 s\n"
          ]
        }
      ],
      "source": [
        "def train(X_train, X_test, y_train, y_test):\n",
        "    st = time.time()\n",
        "    model = LogisticRegression(max_iter=2000)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy, precision, recall, f1 = accuracy_score(y_test, y_pred) , precision_score(y_test, y_pred), recall_score(y_test, y_pred), f1_score(y_test, y_pred)\n",
        "    print(f\"Accuracy:\", accuracy)\n",
        "    print(f\"Precision:\", precision)\n",
        "    print(f\"Recall:\", recall)\n",
        "    print(f\"F1 Score:\", f1)\n",
        "    en = time.time()\n",
        "    print(f\"Time taken: {en - st} s\")\n",
        "\n",
        "\n",
        "train(*train_test_split(scall(data), target, test_size=0.5, random_state=42))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9UQ31XFaRLU"
      },
      "source": [
        "__Выводы__ в свободной форме: Ну дисбаланса классов у нас особо нет, судя по F1, но... У нас само по себе маленькое качество и предсказание почти не отличается от случайного. Для людей, ушедших далеко вперёд (мы вернулись к этому заданию спустя примерно полгода) это ужасное качество"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHvrjAQnaRLW"
      },
      "source": [
        "## Часть 2. Работа с категориальными переменными"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_doKeEKxaRLW"
      },
      "source": [
        "В этой части мы научимся обрабатывать категориальные переменные, так как закодировать их в виде чисел недостаточно (это задаёт некоторый порядок, которого на категориальных переменных может и не быть). Существует два основных способа обработки категориальных значений:\n",
        "- One-hot-кодирование\n",
        "- Счётчики (CTR, mean-target кодирование, ...) — каждый категориальный признак заменяется на среднее значение целевой переменной по всем объектам, имеющим одинаковое значение в этом признаке.\n",
        "\n",
        "Начнём с one-hot-кодирования. Допустим наш категориальный признак $f_j(x)$ принимает значения из множества $C=\\{c_1, \\dots, c_m\\}$. Заменим его на $m$ бинарных признаков $b_1(x), \\dots, b_m(x)$, каждый из которых является индикатором одного из возможных категориальных значений:\n",
        "$$\n",
        "b_i(x) = [f_j(x) = c_i]\n",
        "$$\n",
        "\n",
        "__Задание 1.__ Закодируйте все категориальные признаки с помощью one-hot-кодирования. Обучите логистическую регрессию и посмотрите, как изменилось качество модели (с тем, что было ранее). Измерьте время, потребовавшееся на обучение модели.\n",
        "\n",
        "__(3 балла)__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "GC4tPzPbaRLW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "64060bd7-4d51-46be-8696-597abcdf1840"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           ps_ind_01  ps_ind_02_cat      ps_ind_03  ...  ps_calc_18_bin  ps_calc_19_bin  ps_calc_20_bin\n",
              "count  200000.000000  200000.000000  200000.000000  ...   200000.000000   200000.000000   200000.000000\n",
              "mean        1.984535       1.366685       4.475825  ...        0.287320        0.345090        0.153685\n",
              "std         2.013988       0.674692       2.749082  ...        0.452513        0.475399        0.360647\n",
              "min         0.000000      -1.000000       0.000000  ...        0.000000        0.000000        0.000000\n",
              "25%         0.000000       1.000000       2.000000  ...        0.000000        0.000000        0.000000\n",
              "50%         1.000000       1.000000       4.000000  ...        0.000000        0.000000        0.000000\n",
              "75%         3.000000       2.000000       6.000000  ...        1.000000        1.000000        0.000000\n",
              "max         7.000000       4.000000      11.000000  ...        1.000000        1.000000        1.000000\n",
              "\n",
              "[8 rows x 57 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e524ee1b-b586-4172-8939-95c62b3c68ec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ps_ind_01</th>\n",
              "      <th>ps_ind_02_cat</th>\n",
              "      <th>ps_ind_03</th>\n",
              "      <th>ps_ind_04_cat</th>\n",
              "      <th>ps_ind_05_cat</th>\n",
              "      <th>ps_ind_06_bin</th>\n",
              "      <th>ps_ind_07_bin</th>\n",
              "      <th>ps_ind_08_bin</th>\n",
              "      <th>ps_ind_09_bin</th>\n",
              "      <th>ps_ind_10_bin</th>\n",
              "      <th>ps_ind_11_bin</th>\n",
              "      <th>ps_ind_12_bin</th>\n",
              "      <th>ps_ind_13_bin</th>\n",
              "      <th>ps_ind_14</th>\n",
              "      <th>ps_ind_15</th>\n",
              "      <th>ps_ind_16_bin</th>\n",
              "      <th>ps_ind_17_bin</th>\n",
              "      <th>ps_ind_18_bin</th>\n",
              "      <th>ps_reg_01</th>\n",
              "      <th>ps_reg_02</th>\n",
              "      <th>ps_reg_03</th>\n",
              "      <th>ps_car_01_cat</th>\n",
              "      <th>ps_car_02_cat</th>\n",
              "      <th>ps_car_03_cat</th>\n",
              "      <th>ps_car_04_cat</th>\n",
              "      <th>ps_car_05_cat</th>\n",
              "      <th>ps_car_06_cat</th>\n",
              "      <th>ps_car_07_cat</th>\n",
              "      <th>ps_car_08_cat</th>\n",
              "      <th>ps_car_09_cat</th>\n",
              "      <th>ps_car_10_cat</th>\n",
              "      <th>ps_car_11_cat</th>\n",
              "      <th>ps_car_11</th>\n",
              "      <th>ps_car_12</th>\n",
              "      <th>ps_car_13</th>\n",
              "      <th>ps_car_14</th>\n",
              "      <th>ps_car_15</th>\n",
              "      <th>ps_calc_01</th>\n",
              "      <th>ps_calc_02</th>\n",
              "      <th>ps_calc_03</th>\n",
              "      <th>ps_calc_04</th>\n",
              "      <th>ps_calc_05</th>\n",
              "      <th>ps_calc_06</th>\n",
              "      <th>ps_calc_07</th>\n",
              "      <th>ps_calc_08</th>\n",
              "      <th>ps_calc_09</th>\n",
              "      <th>ps_calc_10</th>\n",
              "      <th>ps_calc_11</th>\n",
              "      <th>ps_calc_12</th>\n",
              "      <th>ps_calc_13</th>\n",
              "      <th>ps_calc_14</th>\n",
              "      <th>ps_calc_15_bin</th>\n",
              "      <th>ps_calc_16_bin</th>\n",
              "      <th>ps_calc_17_bin</th>\n",
              "      <th>ps_calc_18_bin</th>\n",
              "      <th>ps_calc_19_bin</th>\n",
              "      <th>ps_calc_20_bin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.00000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.984535</td>\n",
              "      <td>1.366685</td>\n",
              "      <td>4.475825</td>\n",
              "      <td>0.427785</td>\n",
              "      <td>0.498775</td>\n",
              "      <td>0.354095</td>\n",
              "      <td>0.293855</td>\n",
              "      <td>0.175180</td>\n",
              "      <td>0.17687</td>\n",
              "      <td>0.000485</td>\n",
              "      <td>0.001815</td>\n",
              "      <td>0.011305</td>\n",
              "      <td>0.001190</td>\n",
              "      <td>0.014795</td>\n",
              "      <td>7.097650</td>\n",
              "      <td>0.628765</td>\n",
              "      <td>0.150620</td>\n",
              "      <td>0.157775</td>\n",
              "      <td>0.625666</td>\n",
              "      <td>0.470882</td>\n",
              "      <td>0.607556</td>\n",
              "      <td>8.393725</td>\n",
              "      <td>0.801825</td>\n",
              "      <td>-0.442505</td>\n",
              "      <td>0.894515</td>\n",
              "      <td>-0.114750</td>\n",
              "      <td>6.679825</td>\n",
              "      <td>0.879415</td>\n",
              "      <td>0.813875</td>\n",
              "      <td>1.342500</td>\n",
              "      <td>0.992540</td>\n",
              "      <td>62.632245</td>\n",
              "      <td>2.344055</td>\n",
              "      <td>0.385316</td>\n",
              "      <td>0.841750</td>\n",
              "      <td>0.272450</td>\n",
              "      <td>3.113360</td>\n",
              "      <td>0.450418</td>\n",
              "      <td>0.450681</td>\n",
              "      <td>0.451150</td>\n",
              "      <td>2.371435</td>\n",
              "      <td>1.890125</td>\n",
              "      <td>7.689680</td>\n",
              "      <td>3.005820</td>\n",
              "      <td>9.223045</td>\n",
              "      <td>2.341310</td>\n",
              "      <td>8.448270</td>\n",
              "      <td>5.449475</td>\n",
              "      <td>1.441545</td>\n",
              "      <td>2.872185</td>\n",
              "      <td>7.549840</td>\n",
              "      <td>0.123410</td>\n",
              "      <td>0.628155</td>\n",
              "      <td>0.553315</td>\n",
              "      <td>0.287320</td>\n",
              "      <td>0.345090</td>\n",
              "      <td>0.153685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.013988</td>\n",
              "      <td>0.674692</td>\n",
              "      <td>2.749082</td>\n",
              "      <td>0.496383</td>\n",
              "      <td>1.497825</td>\n",
              "      <td>0.478239</td>\n",
              "      <td>0.455527</td>\n",
              "      <td>0.380122</td>\n",
              "      <td>0.38156</td>\n",
              "      <td>0.022017</td>\n",
              "      <td>0.042564</td>\n",
              "      <td>0.105723</td>\n",
              "      <td>0.034476</td>\n",
              "      <td>0.140983</td>\n",
              "      <td>3.563262</td>\n",
              "      <td>0.483136</td>\n",
              "      <td>0.357679</td>\n",
              "      <td>0.364531</td>\n",
              "      <td>0.283914</td>\n",
              "      <td>0.423068</td>\n",
              "      <td>0.780740</td>\n",
              "      <td>2.563911</td>\n",
              "      <td>0.398638</td>\n",
              "      <td>0.821375</td>\n",
              "      <td>2.381902</td>\n",
              "      <td>0.843212</td>\n",
              "      <td>5.523387</td>\n",
              "      <td>0.406577</td>\n",
              "      <td>0.389208</td>\n",
              "      <td>0.972316</td>\n",
              "      <td>0.089467</td>\n",
              "      <td>33.218457</td>\n",
              "      <td>0.840711</td>\n",
              "      <td>0.061116</td>\n",
              "      <td>0.244495</td>\n",
              "      <td>0.365705</td>\n",
              "      <td>0.694621</td>\n",
              "      <td>0.286845</td>\n",
              "      <td>0.285969</td>\n",
              "      <td>0.286302</td>\n",
              "      <td>1.115503</td>\n",
              "      <td>1.136679</td>\n",
              "      <td>1.329891</td>\n",
              "      <td>1.414704</td>\n",
              "      <td>1.461628</td>\n",
              "      <td>1.245149</td>\n",
              "      <td>2.904012</td>\n",
              "      <td>2.340659</td>\n",
              "      <td>1.206416</td>\n",
              "      <td>1.690382</td>\n",
              "      <td>2.749935</td>\n",
              "      <td>0.328908</td>\n",
              "      <td>0.483299</td>\n",
              "      <td>0.497151</td>\n",
              "      <td>0.452513</td>\n",
              "      <td>0.475399</td>\n",
              "      <td>0.360647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.141421</td>\n",
              "      <td>0.309258</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.551135</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.316228</td>\n",
              "      <td>0.685113</td>\n",
              "      <td>0.330303</td>\n",
              "      <td>2.828427</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.753741</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.387298</td>\n",
              "      <td>0.787037</td>\n",
              "      <td>0.368782</td>\n",
              "      <td>3.316625</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>1.052675</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.424264</td>\n",
              "      <td>0.940349</td>\n",
              "      <td>0.397492</td>\n",
              "      <td>3.605551</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>3.197753</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.264911</td>\n",
              "      <td>3.720626</td>\n",
              "      <td>0.631664</td>\n",
              "      <td>3.741657</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e524ee1b-b586-4172-8939-95c62b3c68ec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e524ee1b-b586-4172-8939-95c62b3c68ec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e524ee1b-b586-4172-8939-95c62b3c68ec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-31b025b6-88ab-4287-9865-56e136ba9681\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-31b025b6-88ab-4287-9865-56e136ba9681')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-31b025b6-88ab-4287-9865-56e136ba9681 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izITXcOWaRLW"
      },
      "source": [
        "Как можно было заменить, one-hot-кодирование может сильно увеличивать количество признаков в датасете, что сказывается на памяти, особенно, если некоторый признак имеет большое количество значений. Эту проблему решает другой способ кодирование категориальных признаков — счётчики. Основная идея в том, что нам важны не сами категории, а значения целевой переменной, которые имеют объекты этой категории. Каждый категориальный признак мы заменим средним значением целевой переменной по всем объектам этой же категории:\n",
        "$$\n",
        "g_j(x, X) = \\frac{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)][y_i = +1]}{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)]}\n",
        "$$\n",
        "\n",
        "__Задание 2.__ Закодируйте категориальные переменные с помощью счётчиков (ровно так, как описано выше без каких-либо хитростей). Обучите логистическую регрессию и посмотрите на качество модели на тестовом множестве. Сравните время обучения с предыдущим экспериментов. Заметили ли вы что-то интересное?\n",
        "\n",
        "__(2 балла)__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "vJmhJjcyaRLW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "169f64ea-bd98-4c21-b313-37b4aacb5956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.59458\n",
            "Precision: 0.6022219825261569\n",
            "Recall: 0.5581079189907835\n",
            "F1 Score: 0.5793263743333265\n",
            "Time taken: 2.7253832817077637 s\n"
          ]
        }
      ],
      "source": [
        "categorical_features = [c for c in data.columns if c.endswith('_cat')]\n",
        "\n",
        "encoder = OHE(sparse_output=False, drop=\"first\")\n",
        "encoded_features = encoder.fit_transform(data[categorical_features])\n",
        "\n",
        "data_one_hot = data.drop(categorical_features, axis=1)\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_features))\n",
        "\n",
        "data_one_hot.reset_index(inplace=True, drop=True)\n",
        "data_one_hot = pd.concat([data_one_hot, encoded_df], axis=1)\n",
        "\n",
        "train(*train_test_split(scall(data_one_hot), target, test_size=0.5, random_state=73))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ6BybtVaRLW"
      },
      "source": [
        "__Вывод:__ Качество выросло немножко. Из своего маленького опыта могу сказать, что OHE не всегда применять оправданно. Как минимум это усложняет анализ и интерпретацию датасета (ну можно тогда его применить после). Ну очевидно есть и плюсы. Именно они дали прирост"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUSCGlbhaRLW"
      },
      "source": [
        "Отметим, что такие признаки сами по себе являются классификаторами и, обучаясь на них, мы допускаем \"утечку\" целевой переменной в признаки. Это ведёт к переобучению, поэтому считать такие признаки необходимо таким образом, чтобы при вычислении для конкретного объекта его целевая метка не использовалась. Это можно делать следующими способами:\n",
        "- вычислять значение счётчика по всем объектам расположенным выше в датасете (например, если у нас выборка отсортирована по времени)\n",
        "- вычислять по фолдам, то есть делить выборку на некоторое количество частей и подсчитывать значение признаков по всем фолдам кроме текущего (как делается в кросс-валидации)\n",
        "- внесение некоторого шума в посчитанные признаки (необходимо соблюсти баланс между избавление от переобучения и полезностью признаков).\n",
        "\n",
        "__Задание 3.__ Реализуйте корректное вычисление счётчиков двумя из трех вышеперчисленных способов, сравните. Снова обучите логистическую регрессию, оцените качество. Сделайте выводы.\n",
        "\n",
        "__(3 балла)__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "По объектам выше в датасете"
      ],
      "metadata": {
        "id": "NDjWQW02gO0y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "YX9gBIEJaRLW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cac75569-6277-4197-f4b7-640127428a9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5972\n",
            "Precision: 0.6017558368852981\n",
            "Recall: 0.5689395913948313\n",
            "F1 Score: 0.5848877712966589\n",
            "Time taken: 0.5351383686065674 s\n"
          ]
        }
      ],
      "source": [
        "X = data.copy()\n",
        "y = target.copy()\n",
        "for feature in categorical_features:\n",
        "    ind = 0\n",
        "    ans = []\n",
        "    mp = {}\n",
        "    for j in X[feature].tolist():\n",
        "        mp[j] = mp.get(j, [0, 0])\n",
        "        mp[j][0] += y[ind]\n",
        "        mp[j][1] += 1\n",
        "        ans.append(mp[j][0] / mp[j][1])\n",
        "        ind += 1\n",
        "    X[feature] = pd.Series(ans, index=X[feature].index)\n",
        "\n",
        "train(*train_test_split(scall(X), y, test_size=0.5, random_state=42))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "По фолдам"
      ],
      "metadata": {
        "id": "CUTG-o5JgTld"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUTDgsR2aGqp",
        "outputId": "f7f8d1a0-fbd7-4118-f2f9-0b93199c2506"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6138\n",
            "Precision: 0.6178373285878781\n",
            "Recall: 0.5916755217835876\n",
            "F1 Score: 0.6044734847708978\n",
            "Time taken: 0.4910874366760254 s\n"
          ]
        }
      ],
      "source": [
        "X = data.copy()\n",
        "y = target.copy()\n",
        "B = int(len(X) ** 0.5)\n",
        "\n",
        "for feature in categorical_features:\n",
        "    lst = X[feature].to_list()\n",
        "    cnts = [{} for j in range(len(X) // B + 2)]\n",
        "    sums = [{} for j in range(len(X) // B + 2)]\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        m = i // B\n",
        "        if len(cnts[m]) == 0:\n",
        "            cnts[m + 1] = cnts[m].copy()\n",
        "            sums[m + 1] = sums[m].copy()\n",
        "        cnts[m + 1][lst[i]] = cnts[m + 1].get(lst[i], 0) + 1\n",
        "        sums[m + 1][lst[i]] = sums[m + 1].get(lst[i], 0) + y[i]\n",
        "\n",
        "    ind = 0\n",
        "    ans = []\n",
        "    for j in X[feature].tolist():\n",
        "        m = ind// B\n",
        "        sum = sums[m].get(j, 0) + sums[-1].get(j, 0) - sums[m + 1].get(j, 0)\n",
        "        cnt = cnts[m].get(j, 0) + cnts[-1].get(j, 0) - cnts[m + 1].get(j, 0)\n",
        "        ans.append(0 if cnt == 0 else sum / cnt)\n",
        "        ind += 1\n",
        "\n",
        "    X[feature] = pd.Series(ans, index=X[feature].index)\n",
        "\n",
        "train(*train_test_split(scall(X), y, test_size=0.5, random_state=42))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIXbvzlWaRLX"
      },
      "source": [
        "__Вывод:__ От фолдов мы получили прирост качества примерно на 2 процента. Это уже хоть что-то, но, возможно, было бы лучше использовать другую модель для обучения..."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}